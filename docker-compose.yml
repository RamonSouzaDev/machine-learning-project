services:
  ml-study:
    build: .
    container_name: ml-study-container
    volumes:
      - .:/app
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    ports:
      - "8000:8000"
    environment:
      - PYTHONPATH=/app
    command: ["python", "main.py"]

  jupyter:
    build: .
    container_name: ml-study-jupyter
    volumes:
      - .:/app
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    ports:
      - "8888:8888"
    environment:
      - PYTHONPATH=/app
    command: ["jupyter", "notebook", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root"]

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: ml-study-mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
      - ./models:/models
    environment:
      - MLFLOW_TRACKING_URI=http://localhost:5000
    command: ["mlflow", "server", "--host", "0.0.0.0", "--port", "5000", "--backend-store-uri", "/mlruns"]

  streamlit:
    build: .
    container_name: ml-study-streamlit
    volumes:
      - .:/app
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
    ports:
      - "8501:8501"
    environment:
      - PYTHONPATH=/app
    command: ["streamlit", "run", "scripts/streamlit_app.py", "--server.port", "8501", "--server.address", "0.0.0.0"]